{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture notes for 2017-04-22\n",
    "\n",
    "## Taylor revisited\n",
    "\n",
    "Though we have mentioned optimization problems intermittently through\n",
    "the last few lectures, we have focused mainly on the problem of finding\n",
    "the solutions of nonlinear equations. We now turn to the problem of\n",
    "finding (local) optima of functions with at least two continuous\n",
    "derivatives.\n",
    "\n",
    "Recall the basic Taylor expansion that we outlined before the break; if\n",
    "$\\phi : {\\mathbb{R}}^n \\rightarrow {\\mathbb{R}}$ is $\\mathcal{C}^2$\n",
    "(i.e. if it is at least twice continuously differentiable) then we have\n",
    "the expansion\n",
    "$$\n",
    "  \\phi(x+u) = \\phi(x) + \\phi'(x) u + \\frac{1}{2} u^T H_{\\phi}(x) u + o(\\|u\\|^2)\n",
    "$$\n",
    "where $\\phi'(x) \\in {\\mathbb{R}}^{1 \\times n}$ is the derivative of\n",
    "$\\phi$ and $H_{\\phi}$ is the *Hessian matrix* consisting of second\n",
    "derivatives:\n",
    "$$\n",
    "  (H_\\phi)_{ij} = \\frac{\\partial \\phi}{\\partial x_i \\partial x_j}.\n",
    "$$\n",
    "The *gradient* $\\nabla \\phi(x) = \\phi'(x)^T$ is a column vector (rather\n",
    "than a row vector).\n",
    "\n",
    "If $\\nabla \\phi(x) \\neq 0$ then $\\nabla \\phi(x)$ and $-\\nabla \\phi(x)$\n",
    "are the directions of steepest ascent and descent, respectively. If\n",
    "$\\nabla \\phi(x) = 0$, then we say $x$ is a *stationary point* or\n",
    "*critical point*. The first derivative test says that if $x$\n",
    "minimizes $\\phi$ (and $\\phi$ is differentiable) then the gradient of $x$\n",
    "must be zero; otherwise, there is a “downhill” direction, and a point\n",
    "near $x$ achieves a smaller function value.\n",
    "\n",
    "A stationary point does not need to be a local minimizer; it might also\n",
    "be a maximizer, or a saddle point. The *second* derivative test says\n",
    "that for a critical point $x$ to be a (local) minimizer, the Hessian\n",
    "$H_{\\phi}(x)$ must be at least positive semi-definite at a (local)\n",
    "minimizer. If $x$ is a stationary point and $H_{\\phi}$ is strictly\n",
    "positive definite, then $x$ must be a local minimizer; in this case, we\n",
    "call $x$ a *strong* local minimizer.\n",
    "\n",
    "One approach to the problem of minimizing $\\phi$ is to run Newton\n",
    "iteration on the critical point equation $\\nabla \\phi(x) = 0$. The\n",
    "Jacobian of the function $\\nabla \\phi(x)$ is simply the Hessian matrix,\n",
    "so Newton’s iteration for finding the critical point is just\n",
    "$$x_{k+1} = x_k - H_{\\phi}(x_k)^{-1} \\nabla \\phi(x_k).$$ We can derive\n",
    "this in the same way that we derived Newton’s iteration for other\n",
    "nonlinear equations; or we can derive it from finding the critical point\n",
    "of a quadratic approximation to $\\phi$: \n",
    "$$\n",
    "  \\hat{\\phi}(x_k+p_k) =\n",
    "    \\phi(x_k) + \\phi'(x_k) p_k + \\frac{1}{2} p_k^T H_{\\phi}(x_k) p_k.\n",
    "$$\n",
    "The critical point occurs for\n",
    "$p_k = -H_{\\phi}(x_k)^{-2} \\nabla \\phi(x_k)$; but this critical point is\n",
    "a strong local minimum iff $H_{\\phi}(x_k)$ is positive definite.\n",
    "\n",
    "There are a few reasons we might want to dig deeper:\n",
    "\n",
    "-   As with other systems of nonlinear equations, we might prefer to\n",
    "    avoid a Newton iteration because of the cost of factoring the\n",
    "    Jacobian (in this case, the Hessian matrix, which is the Jacobian of\n",
    "    $\\nabla \\phi$).\n",
    "\n",
    "-   We can take advantage of the fact that this is *not* a general\n",
    "    system of nonlinear equations in devising and analyzing methods.\n",
    "\n",
    "-   If we only seek to solve the critical point equation, we might end\n",
    "    up finding a maximizer or saddle point as easily as a minimizer.\n",
    "\n",
    "For this reason, we will discuss a different class of iterations, the\n",
    "(scaled) gradient descent methods and their relatives. At the end of the\n",
    "day, we will see many of the same ideas that we saw when treating\n",
    "nonlinear equations, but we will get to them by a slightly different\n",
    "path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1.  Give expressions for the gradient and the Hessian of $f(x,y) = 100(y-x^2)^2 + (1-x)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Argue that this function has a unique local minimum at $(1,1)$.  What are the eigenvalues of the Hessian at the minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "One of the simplest optimization methods is the *steepest descent*\n",
    "or *gradient descent* method \n",
    "$$\n",
    "  x_{k+1} = x_k + \\alpha_k p_k\n",
    "$$\n",
    "where $\\alpha_k$ is a *step size* and $p_k = -\\nabla \\phi(x_k)$. To\n",
    "understand the convergence of this method, consider gradient descent\n",
    "with a fixed step size $\\alpha$ for the quadratic model problem\n",
    "$$\n",
    "  \\phi(x) = \\frac{1}{2} x^T A x + b^T x + c\n",
    "$$\n",
    "where $A$ is symmetric positive definite. We have computed the gradient \n",
    "for a quadratic before:\n",
    "$$\n",
    "  \\nabla \\phi(x) = Ax + b,\n",
    "$$\n",
    "which gives us the iteration equation\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha (A x_k + b).\n",
    "$$\n",
    "Subtracting the fixed point equation\n",
    "$$\n",
    "  x_* = x_* - \\alpha (A x_* + b)\n",
    "$$\n",
    "yields the error iteration\n",
    "$$\n",
    "  e_{k+1} = (I-\\alpha A) e_k.\n",
    "$$\n",
    "If $\\{ \\lambda_j \\}$ are the eigenvalues of $A$, then the eigenvalues of $I-\\alpha A$ are\n",
    "$\\{ 1-\\alpha \\lambda_j \\}$. The spectral radius of the iteration matrix\n",
    "is thus \n",
    "$$\n",
    "  \\min \\{ |1-\\alpha \\lambda_j| \\}_j =\n",
    "  \\min \\left( |1-\\alpha \\lambda_{\\min}|, |1-\\alpha \\lambda_{\\max}| \\right).\n",
    "$$\n",
    "The iteration converges provided $\\alpha < 1/\\lambda_{\\max}$, and the\n",
    "optimal $\\alpha$ is\n",
    "$$\n",
    "  \\alpha_* = \\frac{2}{\\lambda_{\\min} + \\lambda_{\\max}},\n",
    "$$\n",
    "which leads to the spectral radius\n",
    "$$\n",
    "  1 - \\frac{2 \\lambda_{\\min}}{\\lambda_{\\min} + \\lambda_{\\max}} =\n",
    "  1 - \\frac{2}{1 + \\kappa(A)}\n",
    "$$\n",
    "where $\\kappa(A) = \\lambda_{\\max}/\\lambda_{\\min}$ is the condition number for\n",
    "the (symmetric positive definite) matrix $A$. If $A$ is ill-conditioned,\n",
    "then, we are forced to take very small steps to guarantee convergence,\n",
    "and convergence may be heart breakingly slow.\n",
    "\n",
    "A simple example with the function $f(x,y) = x^2 + 100y^2$ illustrates the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 0 ; 0 100]\n",
    "αopt = 2.0 / 101\n",
    "\n",
    "x = zeros(2,100)\n",
    "x[:,1] = [1; 1]\n",
    "for j = 2:100\n",
    "    x[:,j] = x[:,j-1] - αopt * A*x[:,j-1]\n",
    "end\n",
    "\n",
    "xx = range(-1, 1, length=100)\n",
    "plot(xx, xx, (x,y) -> x^2 + 100*y^2, st=:contour)\n",
    "plot!(x[1,:], x[2,:], linecolor=:black, legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior of steepest descent iteration on a quadratic model problem\n",
    "is indicative of the behavior more generally: if $x_*$ is a strong local\n",
    "minimizer of some general nonlinear $\\phi$, then gradient descent with\n",
    "sufficiently small step size will converge locally to $x_*$. But if\n",
    "$H_{\\phi}(x_*)$ is ill-conditioned, then one has to take small steps,\n",
    "and the rate of convergence can be quite slow.\n",
    "\n",
    "Not all problems are terrible ill-conditioned, and so in many cases\n",
    "simple gradient descent algorithms can work quite well. For\n",
    "ill-conditioned problems, though, we would like to change something\n",
    "about the algorithm. One approach is to keep the gradient descent\n",
    "direction and adapt the step size in a clever way; the Barzelei-Borwein\n",
    "(BB) method and related approaches follow this approach. These\n",
    "remarkable methods deserve to be better known, but in the interest of\n",
    "fitting the course into the semester, we will turn instead to the\n",
    "problem of choosing better directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1.  Consider the *exact line search* strategy where $\\alpha$ is chosen to minimize $\\phi(x_k + \\alpha_k \\nabla \\phi(x_k))$.  For a simple quadratic problem, what is the resulting choice of $\\alpha_k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled gradient descent\n",
    "\n",
    "The *scaled* gradient descent iteration takes the form\n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_k p_k, \\quad M_k p_k = -\\nabla \\phi(x_k).\n",
    "$$\n",
    "where $\\alpha_k$ and $p_k$ are the step size and direction, as before,\n",
    "and $M_k$ is a symmetric positive definite *scaling matrix*.\n",
    "Positive definiteness of $M_k$ guarantees that $p_k$ is a \n",
    "*descent direction*, i.e.\n",
    "$$\n",
    "\\phi'(x_k) p_k = \\nabla \\phi(x_k)^T p_k = -\\nabla \\phi(x_k)^T M_k^{-1} \\nabla \\phi(x_k) < 0;$$\n",
    "this in turn guarantees that if $\\alpha_k$ is sufficiently small, $\\phi(x_{k+1})$\n",
    "will be less than $\\phi(x_k)$ — unless $\\phi(x_k)$ is a stationary point\n",
    "(i.e. $\\nabla \\phi(x_k) = 0$).\n",
    "\n",
    "How does scaling improve on simple gradient descent? Consider again the\n",
    "quadratic model problem $$\\nabla \\phi(x) = Ax + b,$$ and let $M$ and\n",
    "$\\alpha$ be fixed. With a little work, we derive the error iteration\n",
    "$$\n",
    "e_{k+1} = (I-\\alpha MA) e_k\n",
    "$$\n",
    "If $\\alpha M = A^{-1}$, the iteration converges in a single step! \n",
    "Going beyond the quadratic model problem, if\n",
    "$H_{\\phi}(x_k)$ is positive definite, we might choose\n",
    "$M_k = H_{\\phi}(x_k)$ — which would correspond to a Newton step.\n",
    "\n",
    "Of course, $H_{\\phi}(x_k)$ does not have to be positive definite\n",
    "everywhere! Thus, most minimization codes based on Newton scaling use\n",
    "$M_k = H_{\\phi}(x_k)$ when it is positive definite, and otherwise use\n",
    "some modification. One possible modification is to choose a diagonal\n",
    "shift $M_k = H_{\\phi}(x_k) + \\beta I$ where $\\beta$ is sufficiently\n",
    "large to guarantee positive definiteness. Another common approach is to\n",
    "compute a *modified Cholesky* factorization of $H_{\\phi}(x_k)$. The\n",
    "modified Cholesky algorithm looks like ordinary Cholesky, and is\n",
    "identical to ordinary Cholesky when $H_{\\phi}(x_k)$ is positive\n",
    "definite. But rather than stopping when it encounters a negative\n",
    "diagonal in a Schur complement, the modified Cholesky approach replaces\n",
    "that element with something else and proceeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified and quasi-Newton optimizers\n",
    "\n",
    "In the last two lectures, we described a variety of Newton-like methods\n",
    "for solving nonlinear equations that might involve fewer derivative\n",
    "computations and lower cost less per step than Newton iteration. Most of\n",
    "these ideas carry over to optimization problems as well, but with some\n",
    "twists to ensure that steps always move in a descent direction. Some of\n",
    "the variants are:\n",
    "\n",
    "-   **Scaling with an approximate Hessian**: Here we choose $M_k$ to\n",
    "    be a symmetric positive definite matrix that in some sense\n",
    "    approximates $H_{\\phi}(x_k)$ (at least when the Hessian is positive\n",
    "    definite) and for which it is easy to solve linear systems.\n",
    "\n",
    "-   **Inexact Newton steps**: Here we compute a (modified) Newton\n",
    "    step, but inexactly (e.g. using a Krylov subspace method like PCG).\n",
    "\n",
    "-   **Quasi-Newton steps**: The most popular quasi-Newton method for\n",
    "    optimization is the BFGS method (Broyden-Fletcher-Goldfarb-Shanno).\n",
    "    The Broyden in BFGS is the same as the Broyden we saw in the popular\n",
    "    Broyden quasi-Newton method for nonlinear equation solving, but the\n",
    "    update formula itself is a little different. We still seek to\n",
    "    satisfy a secant condition, but in BFGS we also seek to retain\n",
    "    symmetry and positive definiteness of the approximate Hessian\n",
    "    matrix. This is done with a rank two update.\n",
    "\n",
    "    The limited memory BFGS (L-BFGS) method uses only a fixed set of\n",
    "    previous iterates in the Hessian approximation, rather than\n",
    "    considering the entire past convergence history. L-BFGS is one of\n",
    "    the most popular methods for large scale optimization.\n",
    "\n",
    "There are also “Krylov-like” methods for choosing update directions,\n",
    "most prominent of which are the nonlinear conjugate gradient methods.\n",
    "There are many potential nonlinear CG methods; for quadratic objective\n",
    "functions, they are all equivalent, but they differ when applied to more\n",
    "general functions. Newton-like methods may be more effective, but\n",
    "usually require more memory and computation per step. Anderson\n",
    "acceleration (discussed in the last lecture) has also been successfully\n",
    "applied to optimization methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
