{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture notes for 2020-05-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequality constraints\n",
    "\n",
    "Problems with inequality constraints can be reduced to problems with\n",
    "*equality* constraints if we can only figure out which constraints\n",
    "are active at the solution. We use two main strategies to tackle this\n",
    "task:\n",
    "\n",
    "-   *Active set* methods guess which constraints are active, then\n",
    "    solve an equality-constrained problem. If the solution satisfies the\n",
    "    KKT conditions, we are done. Otherwise, we update the guess of the\n",
    "    active set by looking for constraint violations or negative\n",
    "    multipliers. The *simplex method* for linear programs is a\n",
    "    famous active set method. The difficulty with these methods is that\n",
    "    it may take many iterations before we arrive on the correct active\n",
    "    set.\n",
    "\n",
    "-   *Interior point* methods take advantage of the fact that barrier\n",
    "    formulations do not require prior knowledge of the active\n",
    "    constraints; rather, the solutions converge to an appropriate\n",
    "    boundary point as one changes the boundary.\n",
    "\n",
    "Between the two, active set methods often have an edge when it is easy\n",
    "to find a good guess for the constraints. Active set methods are great\n",
    "for families of related problems, because they can be “warm started”\n",
    "with an initial guess for what constraints will be active and for the\n",
    "solution. Many strong modern solvers are based on sequential quadratic\n",
    "programming, a Newton-like method in which the model problems are\n",
    "linearly-constrained quadratic programs that are solved by an active set\n",
    "iteration. In contrast to active set methods, interior point methods\n",
    "spend fewer iterations sorting out which constraints are active, but\n",
    "each iteration may require more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic programs with inequality constraints\n",
    "\n",
    "We now consider a quadratic objective with linear inequality\n",
    "constraints:\n",
    "$$\\begin{aligned}\n",
    "  \\phi(x) &= \\frac{1}{2} x^T H x - x^T d \\\\\n",
    "  c(x) &= A^T x-b \\leq 0,\n",
    "\\end{aligned}$$ \n",
    "where\n",
    "$H \\in {\\mathbb{R}}^{n \\times n}$ is symmetric and positive definite,\n",
    "$A \\in {\\mathbb{R}}^{n \\times m}$ with $m < n$, and\n",
    "$b \\in {\\mathbb{R}}^m$. The KKT conditions for this problem are\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda &= 0 \\\\\n",
    "  A^T x-b & \\leq 0 \\\\\n",
    "  \\lambda & \\geq 0 \\\\\n",
    "  \\lambda_i (A^T x-b)_i &= 0.\n",
    "\\end{aligned}$$\n",
    "The *active set* is the set of $i$ such that $(A^T x-b)_i = 0$. We assume\n",
    "that the active columns of $A$ are always linearly independent\n",
    "(e.g. $0 \\leq x_i$ and $x_i \\leq 1$ can co-exist, but it is not OK to\n",
    "have both $x_i \\leq 1$ and $x_i \\leq 2$).\n",
    "\n",
    "Examples are always good, as are pictures.  We will borrow the following\n",
    "2D example from Nocedal and Wright (Example 16.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective in Nocedal and Wright: ϕ(x) = (x[1]-1.0)^2 + (x[2]-2.5)^2\n",
    "#   We will get rid of a constant term to get it to our usual form (and scale by 1/2)\n",
    "#\n",
    "H = [1.0 0.0; 0.0 1.0]\n",
    "d = [1.0; 2.5]\n",
    "\n",
    "# Constraints per Nocedal and Wright -- we rewrite so the inequality goes the other way\n",
    "#  x1 - 2 x2 + 2 ≥ 0\n",
    "# -x1 - 2 x2 + 6 ≥ 0\n",
    "# -x1 + 2 x2 + 2 ≥ 0\n",
    "#  x1 ≥ 0\n",
    "#  x2 ≥ 0\n",
    "#\n",
    "A = [-1.0  2.0 ;\n",
    "      1.0  2.0 ;\n",
    "      1.0 -2.0 ;\n",
    "     -1.0  0.0 ;\n",
    "      0.0 -1.0 ]'\n",
    "b = [2.0; 6.0; 2.0; 0.0; 0.0]\n",
    "\n",
    "# Draw a plot of the quadratic and the constraints\n",
    "function plot_ex16_3()\n",
    "    q(x,y) = (x-1.0)^2 + (y-2.5)^2\n",
    "    corners = [0.0 0.0 ;\n",
    "               2.0 0.0 ;\n",
    "               4.0 1.0 ;\n",
    "               2.0 2.0 ;\n",
    "               0.0 1.0 ]\n",
    "    xx = range(-1.0, 4.0, length=101)\n",
    "    p = plot(corners[:,1], corners[:,2], st=:shape)\n",
    "    plot!(xx, xx, q, st=:contour, legend=false)\n",
    "    p\n",
    "end\n",
    "\n",
    "plot_ex16_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An active set approach\n",
    "\n",
    "At the $k$th step in an active set QP solver, we update an iterate $x^k$\n",
    "approximating the constrained minimizer *and* we update a\n",
    "corresponding working set $\\mathcal{W}^k$ approximating the active set.\n",
    "A step of this solver looks like:\n",
    "\n",
    "1.  Choose a step $p^k$ by minimizing the quadratic form assuming the\n",
    "    constraints in $\\mathcal{W}^k$ are the active constraints. This\n",
    "    gives an equality-constrained subproblem.\n",
    "\n",
    "2.  If $p^k$ is zero, then\n",
    "\n",
    "    1.  Compute the Lagrange multipliers associated with the set\n",
    "        $\\mathcal{W}^k$.\n",
    "\n",
    "    2.  If all the multipliers are non-negative, terminate.\n",
    "\n",
    "    3.  Otherwise, let $\\lambda_j$ be the most negative multiplier, and\n",
    "        set $\\mathcal{W}^{k+1} = \\mathcal{W}^k \\setminus \\{ j \\}$\n",
    "\n",
    "3.  Otherwise $p^k \\neq 0$.\n",
    "\n",
    "    1.  Advance $x^{k+1} = x^k + \\alpha_k p^k$ where the step length\n",
    "        $\\alpha_k$ is the largest allowed value (up to one) such that\n",
    "        $x^{k+1}$ is feasible.\n",
    "\n",
    "    2.  If $\\alpha_k < 1$, then there is (at least) one *blocking\n",
    "        constraint* $j$ such that $(A^T x^{k+1}-b)_j = 0$ and\n",
    "        $j \\not \\in \\mathcal{W}^k$. Update\n",
    "        $\\mathcal{W}^{k+1} = \\mathcal{W}^k \\cup \\{ j \\}$.\n",
    "\n",
    "If we do not attempt any particular efficiency, this is mostly straightforward to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function qp_as(x0, H, d, A, b; ptol=1e-8, W0=[], nsteps=100, monitor=(x, W)->nothing)\n",
    "\n",
    "    n = length(x0)\n",
    "    m = length(b)\n",
    "    W = zeros(Bool, m)\n",
    "    \n",
    "    x = copy(x0)\n",
    "    p = zeros(n)\n",
    "    λ = zeros(m)\n",
    "    W[W0] .= true\n",
    "    monitor(x, W)\n",
    "\n",
    "    # Compute Cholesky factorization for range space solver\n",
    "    F = cholesky(H)\n",
    "    L = F.L\n",
    "    Y = L\\A\n",
    "    c = L\\d\n",
    "    \n",
    "    for k = 1:nsteps\n",
    "        \n",
    "        ## Solve the equality constrained subproblem (range space method)        \n",
    "        λ[:] .= 0.0\n",
    "        λ[W] = ( Y[:,W]'*Y[:,W] )\\( Y[:,W]'*c - b[W] )\n",
    "        p[:] = L'\\(c-Y[:,W]*λ[W])-x\n",
    "        \n",
    "        if norm(p) < ptol\n",
    "            \n",
    "            # Find most negative multiplier (if there is one)\n",
    "            minλ = 0.0\n",
    "            j = 0\n",
    "            for k = 1:m\n",
    "                if λ[k] < minλ\n",
    "                    minλ = λ[k]\n",
    "                    j = k\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if j == 0\n",
    "                return x      # All multipliers non-negative, done!\n",
    "            else\n",
    "                W[j] = false  # Release jth constraint\n",
    "            end\n",
    "\n",
    "        else\n",
    "            \n",
    "            # Figure out step (and any blocking constraint)\n",
    "            α = 1.0\n",
    "            r = b-A'*x\n",
    "            u = A'*p\n",
    "            blocking_idx = 0\n",
    "            for k = 1:m\n",
    "                if !(k in W) && (α*u[k] > r[k])\n",
    "                    α = r[k]/u[k]\n",
    "                    blocking_idx = k\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            # Take step and update list of active constraints\n",
    "            x[:] += α*p\n",
    "            if blocking_idx > 0\n",
    "                W[blocking_idx] = true\n",
    "            end\n",
    "            monitor(x, W)\n",
    "\n",
    "        end\n",
    "    end\n",
    "    error(\"Did not converge after $nsteps steps\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhist = []\n",
    "xsol = qp_as([2.0; 0.0], H, d, A, b, W0=[3 5], monitor=(x, W) -> push!(xhist, copy(x)))\n",
    "println(\"x = $xsol\")\n",
    "\n",
    "p = plot_ex16_3()\n",
    "plot!([x[1] for x in xhist], [x[2] for x in xhist], marker=true, linewidth=3, linestyle=:dash, color=:black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks about this strategy are in order:\n",
    "\n",
    "-   The strategy is guaranteed not to cycle — the working set at any\n",
    "    given iterate is distinct from the working set at any other iterate.\n",
    "    Assuming the steps are computed exactly (via Newton), the iteration\n",
    "    converges in a finite number of steps. That said, there are an\n",
    "    exponential number of working sets; and, as with the simplex method\n",
    "    for linear programming, there are examples where the algorithm may\n",
    "    have exponential complexity because of the cost of exploring all the\n",
    "    working set. But, as with the simplex method, this is not the common\n",
    "    case.\n",
    "\n",
    "-   The strategy only changes the working set by adding or removing one\n",
    "    constraint at a time. Hence, if $\\mathcal{A}$ is the true active\n",
    "    set, the number of steps required is at least\n",
    "    $|\\mathcal{W}^0| + |\\mathcal{A}| - 2|\\mathcal{W}^0 \\cap \\mathcal{A}|$.\n",
    "    This is bad news if there are many possible constraints and we lack\n",
    "    a good initial guess as to which ones will be active.\n",
    "\n",
    "-   If we compute the steps $p^k$ as described above, the cost per step\n",
    "    (after an initial factorization of the Hessian and triangular solves on the constraints)\n",
    "    would appear to be $O(n^2+n|\\mathcal{W}^k|^2)$. In practice, though,\n",
    "    each linear system differs from the previous system only through the\n",
    "    addition or deletion of a constraint. If we are clever with our\n",
    "    numerical linear algebra, and re-use the factorization work already\n",
    "    invested through updating and downdating, we can reduce the cost per\n",
    "    step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barriers: hard and soft\n",
    "\n",
    "Before we proceed, a word is in order about the relationship between\n",
    "Lagrange multipliers and barriers or penalties. To be concrete, let us\n",
    "consider the inequality-constrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) \\mbox{ s.t. } c(x) \\leq 0,\n",
    "$$ \n",
    "where\n",
    "$c : {\\mathbb{R}}^n \\rightarrow {\\mathbb{R}}^m$ with $m < n$, and the\n",
    "inequality should be interpreted elementwise. In a barrier formulation,\n",
    "we approximate the problem by problems of the form\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) - \\mu \\sum_{j=1}^m \\log(-c_j(x)),\n",
    "$$\n",
    "where the second term shoots to infinity as $c_j(x) \\rightarrow 0$; \n",
    "but for any fixed $c_j(x) < 0$ it becomes negligible once $\\mu$ is small enough.\n",
    "Differentiating this objective gives us the critical point equations\n",
    "$$\n",
    "  \\nabla \\phi(\\hat{x}(\\mu))\n",
    "  -\\sum_{j=1}^m \\frac{\\mu}{c_j(\\hat{x}(\\mu))} \\nabla c_j(\\hat{x}(\\mu)) = 0.\n",
    "$$\n",
    "By way of comparison, if we were to try to exactly optimize this\n",
    "inequality constrained problem, we would want to satisfy the KKT\n",
    "conditions\n",
    "$$\\begin{aligned}\n",
    "  \\nabla \\phi(x) + \\nabla c(x) \\lambda &= 0 \\\\\n",
    "  c(x) & \\leq 0 \\\\\n",
    "  \\lambda & \\geq 0 \\\\\n",
    "  \\lambda_j(x) c_j(x) &= 0.\n",
    "\\end{aligned}$$\n",
    "Comparing the two, we see that the quantities \n",
    "$\\hat{\\lambda}_j(\\mu) \\equiv -\\mu/c_j(x_*(\\mu))$\n",
    "should approximate the Lagrange multipliers: they play the same role in\n",
    "the equation involving the gradient of $\\phi$, they are always positive\n",
    "for $\\mu > 0$, and $\\hat{\\lambda}_j(x_*(\\mu)) \\rightarrow 0$ provided\n",
    "$c_j(x_*(\\mu)) \\not \\rightarrow 0$.\n",
    "\n",
    "I like to think of barriers and penalties in physical terms as being\n",
    "like slightly flexible walls. In real life, when you push on a wall,\n",
    "however stiff, there is a little bit of give. What we see as an opposing\n",
    "force generated by a rigid wall is really associated with that little\n",
    "bit of elastic give. But a good idealization is that of a perfectly\n",
    "rigid wall, which does not give at all. Instead, it responds to conctact\n",
    "with exactly the amount of force normal to the wall surface that is\n",
    "required to counter any force pushing into the wall. That\n",
    "equal-and-opposite force is exactly what is captured by Lagrange\n",
    "multipliers, where the very stiff elastic response is captured by the\n",
    "barrier or penalty formulation, with the parameter $\\mu$ representing\n",
    "the compliance of the barrier (inverse stiffness).\n",
    "\n",
    "The weakness of a penalty or barrier approach is two-fold: if $\\mu$ is\n",
    "far from zero, we have a thick and spongy barrier (a poor approximation\n",
    "to the infinitely rigid case); whereas if $\\mu$ is close to zero, we\n",
    "have a nearly-rigid barrier, but the Hessian of the augmented barrier\n",
    "function becomes very ill-conditioned, scaling like $\\mu^{-1}$. In\n",
    "contrast, with a Lagrange multiplier formulation, we have a perfect\n",
    "barrier and no problems with ill-conditioning, but at the cost of having\n",
    "to explicitly determine whether the optimum is at one or more of the\n",
    "constraint surfaces, and also what “contact forces” are needed to\n",
    "balance the negative gradient of $\\phi$ that pushes into the barrier.\n",
    "\n",
    "Several modern algorithmic approaches, such as augmented Lagrangian and\n",
    "interior point methods, get the best of both perspectives by combining a\n",
    "penalty or barrier term with a Lagrange multiplier computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interior point strategy\n",
    "\n",
    "Having touched on the relation between Lagrange multipliers and\n",
    "logarithmic barriers, let us now turn to an interior point method for\n",
    "quadratic programming. We start by rewriting the constraints\n",
    "$A^Tx - b \\leq 0$ in terms of an extra set of slack variables:\n",
    "$$y = b-A^Tx \\geq 0.$$ With this definition, we write the KKT conditions\n",
    "as\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda & = 0 \\\\\n",
    "  A^T x-b+y &= 0 \\\\\n",
    "  \\lambda_i y_i &= 0 \\\\\n",
    "  y_i, \\lambda_i & \\geq 0.\n",
    "\\end{aligned}$$\n",
    "Interior point methods solve this system by applying Newton-like iterations \n",
    "to the three equations, while at the same time ensuring that the inequalities\n",
    "are enforced strictly at every step (that is, every step is interior to the feasible\n",
    "domain).\n",
    "\n",
    "Compare this to the critical point conditions for the barrier problem\n",
    "$$\n",
    "  \\mbox{minimize } \\frac{1}{2} x^T H x - x^T d - \\gamma \\sum_{j=1}^m \\log(y_j)\n",
    "$$\n",
    "for some small value of the barrier parameter $\\gamma$, where we note\n",
    "that\n",
    "$$\n",
    "  \\nabla_x \\left( -\\gamma \\sum_{j=1}^n \\log(y_j) \\right) =\n",
    "  A \\hat{\\lambda}, \\quad \\hat{\\lambda}_j = \\frac{\\gamma}{y_j}\n",
    "$$\n",
    "and we can rewrite this system as\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda &= 0 \\\\\n",
    "  A^T x - b + y &= 0 \\\\\n",
    "  y_i \\lambda_i - \\gamma &= 0.\n",
    "\\end{aligned}$$\n",
    "Typical interior point methods take guarded Newton steps (or Newton-like steps)\n",
    "on this system of equations, which can be regarded as a relaxation of the KKT\n",
    "conditions or as a critical point of a barrier formulation.  The path traced out\n",
    "as $\\mu$ varies is known as the \"central path.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function barrier_qp(x0, H, d, A, b, γ; nsteps=20, ptol=1e-8)\n",
    "\n",
    "    n = length(d)\n",
    "    m = length(b)\n",
    "    σ = 0.5\n",
    "\n",
    "    x = copy(x0)\n",
    "    y = b-A'*x\n",
    "    λ = γ./y\n",
    "    \n",
    "    F(x, y, λ) = [H*x - d + A*λ; \n",
    "                  A'*x - b + y;\n",
    "                  y.*λ .- γ]\n",
    "    J(x, y, λ) = [H          zeros(n,m)  A;\n",
    "                  A'         I           zeros(m,m);\n",
    "                  zeros(m,n) diagm(λ)    diagm(y)]\n",
    "    \n",
    "    α = 1.0    \n",
    "    p = -(J(x, y, λ) \\ F(x, y, λ))\n",
    "    for k = 1:nsteps\n",
    "        xnew = x + α*p[1:n]\n",
    "        if all(A'*xnew-b .<= 0.0)\n",
    "            x = xnew\n",
    "            y += α*p[n+1:n+m]\n",
    "            λ += α*p[n+m+1:end]\n",
    "            if α == 1.0 && norm(p) < ptol\n",
    "                return x, λ\n",
    "            end\n",
    "            α = 1.0\n",
    "            p = -(J(x, y, λ) \\ F(x, y, λ))\n",
    "        else\n",
    "            α /= 2.0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    error(\"Did not converge in $nsteps steps\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2.0; 1.0]\n",
    "\n",
    "p = plot_ex16_3()\n",
    "plot!([x[1]], [x[2]], marker=true, color=:black)\n",
    "for s = 1:10\n",
    "    x, λ = barrier_qp(x, H, d, A, b, 2.0^(1-s))\n",
    "    plot!([x[1]], [x[2]], marker=true, color=:black)\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\gamma$ is adjusted dynamically during the solve, and is\n",
    "usually written as $\\gamma = \\sigma \\mu$ where $\\sigma \\in [0,1]$ is the\n",
    "centering parameters and $\\mu = y^T \\lambda / m$ is the\n",
    "*complimentarity measure*, which should go to zero as we approach a\n",
    "problem solution.  Getting all the details right is somewhat complicated,\n",
    "though, and we recommend using a package written by someone with some\n",
    "expertise.\n",
    "\n",
    "Interior point methods avoid the problem of having to do a combinatorial\n",
    "search to figure out the correct active set. At the same time, active\n",
    "set methods may be more efficient for problems where we have a good\n",
    "initial guess at the active set. Neither approach is universally\n",
    "preferable.  Indeed, it is possible to take a hybrid approach where an\n",
    "interior point method (or something similar) is used to estimate \n",
    "which constraints are actually active, and then an active set method\n",
    "serves to \"clean up\" the solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
