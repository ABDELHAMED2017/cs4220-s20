{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture notes for 2020-05-01\n",
    "\n",
    "## Consider constraints\n",
    "\n",
    "So far, we have considered *unconstrained* optimization problems.\n",
    "The *constrained* problem is\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) \\mbox{ s.t. } x \\in \\Omega\n",
    "$$\n",
    "where $\\Omega \\subset {\\mathbb{R}}^n$. We usually define $x$ in terms of a\n",
    "collection of constraint equations and inequalities:\n",
    "$$\n",
    "  \\Omega = \\{ x \\in {\\mathbb{R}}^n :\n",
    "  c_i(x) = 0, i \\in \\mathcal{E} \\mbox{ and }\n",
    "  c_i(x) \\leq 0, i \\in \\mathcal{I} \\}.\n",
    "$$\n",
    "We will suppose throughout our discussions that both $\\phi$ and all the\n",
    "functions $c$ are differentiable.\n",
    "\n",
    "If $x_*$ is a solution to the constrained minimization problem, we say\n",
    "constraint $i \\in \\mathcal{I}$ is *active* if $c_i(x) = 0$. Often,\n",
    "the hard part of solving constrained optimization problems is figuring\n",
    "out which constraints are active. From this perspective, the equality\n",
    "constrained problem sits somewhere in difficulty between the\n",
    "unconstrained problem and the general constrained problem.\n",
    "\n",
    "Our treatment of constrained optimization is necessarily brief; but in\n",
    "the next two lectures, I hope to lay out some of the big ideas. Today we\n",
    "will focus on formulations; next time, algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three recipes\n",
    "\n",
    "Most methods for constrained optimization involve a reduction to an\n",
    "unconstrained problem (or subproblem). There are three ways such a\n",
    "reduction might work:\n",
    "\n",
    "-   We might *remove* variables by eliminating constraints.\n",
    "\n",
    "-   We might keep the *same* number of variables and try to fold the\n",
    "    constraints into the objective function.\n",
    "\n",
    "-   We might *add* variables to enforce constraints via the method\n",
    "    of Lagrange multipliers.\n",
    "\n",
    "These approaches are not mutually exclusive, and indeed one often\n",
    "alternates between perspectives in modern optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint elimination\n",
    "\n",
    "The idea of constraint elimination is straightforward. Suppose we want\n",
    "to solve an optimization problem with only equality constraints:\n",
    "$c_i(x) = 0$ for $i \\in \\mathcal{E}$, where $|\\mathcal{E}| < n$ and the\n",
    "constraints are independent – that is, the $|\\mathcal{E}| \\times n$\n",
    "Jacobiam matrix $\\partial c / \\partial x$ has full row rank. Then we can\n",
    "think (locally) of $x$ satisfying the constraints in terms of an\n",
    "implicitly defined function $x = g(y)$ for\n",
    "$y \\in {\\mathbb{R}}^{n-|\\mathcal{E}|}$. If this characterization can be\n",
    "made global, then we can solve the unconstrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(g(y))\n",
    "$$\n",
    "over all $y \\in {\\mathbb{R}}^{n-|\\mathcal{E}|}$.\n",
    "\n",
    "The difficulty with constraint elimination is that it requires that we\n",
    "find a global parameterization of the solutions to the constraint\n",
    "equations. This is usually difficult. An exception is when the\n",
    "constraints are *linear*: \n",
    "$$\n",
    "  c(x) = A^T x - b\n",
    "$$\n",
    "In this case, the feasible set $\\Omega = \\{ x : A^T x - b = 0 \\}$ can be\n",
    "written as $x \\in \\{ x^p + z : z \\in \\mathcal{N}(A) \\}$, where $x^p$ is a\n",
    "*particular solution* and $\\mathcal{N}(A)$ is the null space of $A$.\n",
    "We can find both a particular solution and the null space by doing a\n",
    "full QR decomposition on $A$:\n",
    "$$\n",
    "  A = \\begin{bmatrix} Q_1 & Q_2 \\end{bmatrix}\n",
    "      \\begin{bmatrix} R_1 \\\\ 0 \\end{bmatrix}.\n",
    "$$\n",
    "Then solutions to the constraint equations have the form \n",
    "$$\n",
    "  x = A^\\dagger b + Q_2 y = Q_1 R_1^{-T} b + Q_2 y\n",
    "$$\n",
    "where the first term is a particular solution and the second term gives a\n",
    "vector in the null space.\n",
    "\n",
    "For problems with linear equality constraints, constraint elimination\n",
    "has some attractive properties. If there are many constraints, the\n",
    "problem after constraint elimination may be much smaller. And if the\n",
    "original problem was convex, then so is the reduced problem, and with a\n",
    "better-conditioned Hessian matrix. The main drawback is that we may lose\n",
    "sparsity of the original problem. Constraint elimination is also\n",
    "attractive for solving equality-constrained subproblems in optimization\n",
    "algorithms for problems with linear *inequality* constraints,\n",
    "particularly if those constraints are simple (e.g. elementwise\n",
    "non-negativity of the solution vector).\n",
    "\n",
    "For problems with more complicated equality constraints, constraint\n",
    "elimination is hard. Moreover, it may not be worthwhile; in some cases,\n",
    "eliminating constraints results in problems that are smaller than the\n",
    "original formulation, but are harder to solve.\n",
    "\n",
    "The idea of constraint elimination is not limited to equality\n",
    "constraints: one can also sometimes use an alternate parameterization to\n",
    "convert simple inequality-constrained problems to unconstrained\n",
    "problems. For example, if we want to solve a non-negative optimization\n",
    "problem (all $x_i \\geq 0$), we might write $x_i = y_i^2$, or possibly\n",
    "$x_i = \\exp(y_i)$ (though in this case we would need to let\n",
    "$y_i \\rightarrow -\\infty$ to exactly hit the constraint). But while they\n",
    "eliminate constraints, these re-parameterizations can also destroy nice\n",
    "features of the original problem (e.g. convexity). So while such\n",
    "transformations are a useful part of the computational arsenal, they\n",
    "should be treated as one tool among many, and not always as the best\n",
    "tool available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalties and barriers\n",
    "\n",
    "Constraint elimination methods convert a constrained to an unconstrained\n",
    "problem by changing the coordinate system in which the problem is posed.\n",
    "Penalty and barrier methods accomplish the same reduction to the\n",
    "unconstrained case by changing the function.\n",
    "\n",
    "As an example of a *penalty* method, consider the problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) + \\frac{1}{2\\mu} \\sum_{i\\in \\mathcal{E}}\n",
    "  c_i(x)^2 + \\frac{1}{2\\mu} \\sum_{i \\in \\mathcal{I}} \\max(c_i(x),0)^2.\n",
    "$$\n",
    "When the constraints are violated ($c_i > 0$ for inequality constraints\n",
    "and $c_i \\neq 0$ for equality constraints), the extra terms (penalty\n",
    "terms) beyond the original objective function are positive; and as\n",
    "$\\mu \\rightarrow 0$, those penalty terms come to dominate the behavior\n",
    "outside the feasible region. Hence as we let $\\mu \\rightarrow 0$, the\n",
    "solutions to the penalized problem approach solutions to the original\n",
    "(true) problem. At the same time, as $\\mu \\rightarrow 0$ we have much\n",
    "wilder derivatives of $\\phi$, and the optimization problems become more\n",
    "and more problematic from the perspective of conditioning and numerical\n",
    "stability. Penalty methods also have the potentially undesirable property\n",
    "that if any constraints are active at the true solution, the solutions to\n",
    "the penalty problem tend to converge from *outside* the feasible region.\n",
    "This poses a significant problem if, for example, the original objective function\n",
    "$\\phi$ is undefined outside the feasible region.\n",
    "\n",
    "As an example of a *barrier* method, consider the purely inequality\n",
    "constrained case, and approximate the original constrained problem by\n",
    "the unconstrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) - \\mu \\sum_{i \\in \\mathcal{I}} \\log(-c_i(x)).\n",
    "$$\n",
    "As $c_i(x)$ approaches zero from below, the barrier term\n",
    "$-\\mu \\log (-c_i(x))$ grows rapidly; but at any fixed $x$ in the\n",
    "interior of the domain, the barrier goes to zero as $\\mu$ goes to zero.\n",
    "Hence, as $\\mu \\rightarrow 0$ through positive values, the solution to\n",
    "the barrier problem approaches the solution to the true problem through\n",
    "a sequence of *feasible* points (i.e. approximate solutions that\n",
    "satisfy the constraints). Though the feasibility of the approximations\n",
    "is an advantage over penalty based formulations, interior formulations\n",
    "share with penalty formulations the disadvantage that the solutions for\n",
    "$\\mu > 0$ lie at points with increasingly large derivatives (and bad\n",
    "conditioning) if the true solution has active constraints.\n",
    "\n",
    "There are *exact penalty* formulations for which the solution to the\n",
    "penalized problem is an exact solution for the original problem. Suppose\n",
    "we have an inequality constrained problem in which the feasible region\n",
    "is closed and bounded, each constraint $c_i$ has continuous derivatives,\n",
    "and $\\nabla c_i(x) \\neq 0$ at any boundary point $x$ where constraint\n",
    "$i$ is active. Then the solution to the problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) + \\frac{1}{\\mu} \\sum_i \\max(c_i(x), 0)\n",
    "$$\n",
    "is *exactly* the solution to the original constrained optimization\n",
    "problem for some $\\mu > 0$. In this case, we used a\n",
    "*nondifferentiable* exact penalty, but there are also exact\n",
    "differentiable penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrange multipliers\n",
    "\n",
    "Picture a function $\\phi : {\\mathbb{R}}^n \\rightarrow {\\mathbb{R}}$; if\n",
    "you’d like to be concrete, let $n = 2$. Absent a computer, we might\n",
    "optimize of $\\phi$ by the physical experiment of dropping a tiny ball\n",
    "onto the surface and watching it roll downhill (in the steepest descent\n",
    "direction) until it reaches the minimum. If we wanted to solve a\n",
    "constrained minimization problem, we could build a great wall between\n",
    "the feasible and the infeasible region. A ball rolling into the wall\n",
    "would still roll freely in directions tangent to the wall (or away from\n",
    "the wall) if those directions were downhill; at a constrained miminizer,\n",
    "the force pulling the ball downhill would be perfectly balanced against\n",
    "an opposing force pushing into the feasible region in the direction of\n",
    "the normal to the wall. If the feasible region is $\\{x : c(x) \\leq 0\\}$,\n",
    "the normal direction pointing inward at a boundary point $x_*$\n",
    "s.t. $c(x_*) = 0$ is proportional to $-\\nabla c(x_*)$. Hence, if $x_*$\n",
    "is a constrained minimum, we expect the sum of the “rolling downhill”\n",
    "force ($-\\nabla \\phi$) and something proportional to $-\\nabla c(x_*)$ to\n",
    "be zero: \n",
    "$$\n",
    "  -\\nabla \\phi(x_*) - \\mu \\nabla c(x_*) = 0.\n",
    "$$\n",
    "The *Lagrange multiplier* $\\mu$ in this picture represents the magnitude of the\n",
    "restoring force from the wall balancing the tendency to roll downhill.\n",
    "\n",
    "More abstractly, and more generally, suppose that we have a mix of\n",
    "equality and inequality constraints. We define the *Lagrangian* \n",
    "$$\n",
    "  L(x, \\lambda, \\mu) = \\phi(x) +\n",
    "    \\sum_{i \\in \\mathcal{E}} \\lambda_i c_i(x) +\n",
    "    \\sum_{i \\in \\mathcal{I}} \\mu_i c_i(x).\n",
    "$$\n",
    "The *Karush-Kuhn-Tucker (KKT) conditions* for $x_*$ to be a constrained minimizer are\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\nabla_x L(x_*) &= 0 \\\\\n",
    "  c_i(x_*) &= 0, \\quad i \\in \\mathcal{E}\n",
    "  & \\mbox{equality constraints}\\\\\n",
    "  c_i(x_*) & \\leq 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{inequality constraints}\\\\\n",
    "  \\mu_i & \\geq 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{non-negativity of multipliers}\\\\\n",
    "  c_i(x_*) \\mu_i &= 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{complementary slackness}\n",
    "\\end{aligned}$$ \n",
    "where the (negative of) the “total force” at $x_*$ is \n",
    "$$\n",
    "  \\nabla_x L(x_*) = \\nabla \\phi(x_*) +\n",
    "    \\sum_{i\\in \\mathcal{E}} \\lambda_i \\nabla c_i(x_*) +\n",
    "    \\sum_{i\\in \\mathcal{I}} \\mu_i \\nabla c_i(x_*).\n",
    "$$\n",
    "The complementary slackness condition corresponds to the idea that a multiplier \n",
    "should be nonzero only if the corresponding constraint is active (a “restoring\n",
    "force” is only present if our test ball is pushed into a wall).\n",
    "\n",
    "Like the critical point equation in the unconstrained case, the KKT\n",
    "conditions define a set of (necessary but not sufficient) nonlinear\n",
    "algebraic equations that must be satisfied at a minimizer. Because of\n",
    "the multipliers, we have *more* variables than were present in the\n",
    "original problem. However, the Jacobian matrix (KKT matrix)\n",
    "$$\n",
    "  J = \\begin{bmatrix}\n",
    "    \\nabla^2_x L(x_*) & \\nabla c \\\\\n",
    "    (\\nabla c)^T & 0\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "has a saddle point structure even when $\\nabla^2_x \\phi$\n",
    "is positive definite. Also, unlike the penalty and barrier approaches\n",
    "described before, the Lagrange multiplier approach requires that we\n",
    "figure out which multipliers are active or not — an approach that seems\n",
    "to lead to a combinatorial search in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "What would you like clarified in these notes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer*:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
